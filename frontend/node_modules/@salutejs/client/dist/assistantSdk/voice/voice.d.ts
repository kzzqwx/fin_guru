import { createClient } from '../client/client';
import { AppInfo, EmotionId, OriginalMessageType, Mid } from '../../typings';
import { AssistantSettings } from '../assistant';
import { MutexedObject } from '../mutexedObject';
import { VoiceListenerStatus } from './listener/voiceListener';
import { Music2TrackProtocol } from './recognizers/mtt';
export interface TtsEvent {
    status: 'start' | 'stop';
    messageId: number;
    appInfo: AppInfo;
}
export declare const createVoice: (client: ReturnType<typeof createClient>, settings: MutexedObject<AssistantSettings>, emit: (event: {
    asr?: {
        text: string;
        last?: boolean | undefined;
        mid?: Mid | undefined;
    } | undefined;
    emotion?: EmotionId | undefined;
    listener?: {
        status: VoiceListenerStatus;
    } | undefined;
    mtt?: {
        response: Music2TrackProtocol.MttResponse;
        mid: OriginalMessageType['messageId'];
    } | undefined;
    tts?: TtsEvent | undefined;
    voiceAnalyser?: {
        data: Uint8Array;
    } | undefined;
}) => void, onReady?: (() => void) | undefined, useAnalyser?: boolean | undefined) => {
    destroy: () => void;
    listen: ({ begin }?: {
        begin?: Uint8Array[] | undefined;
    }, isAutoListening?: boolean | undefined) => Promise<void>;
    shazam: () => Promise<void>;
    sendVoice: (chunks: Uint8Array[], messageName?: "MUSIC_RECOGNITION" | undefined) => Promise<void>;
    streamVoice: (chunks: Uint8Array[], last: boolean, messageName?: 'MUSIC_RECOGNITION' | undefined) => Promise<void>;
    stop: () => void;
    stopPlaying: () => void;
};
//# sourceMappingURL=voice.d.ts.map